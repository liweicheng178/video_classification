{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 775
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 39833,
     "status": "ok",
     "timestamp": 1586045135840,
     "user": {
      "displayName": "Wood Xu",
      "photoUrl": "",
      "userId": "11462779557016257409"
     },
     "user_tz": -480
    },
    "id": "MpxsElxBuG1i",
    "outputId": "5c08384e-f01c-49e1-9956-634cd6138891"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  3727  100  3727    0     0  67763      0 --:--:-- --:--:-- --:--:-- 67763\n",
      "Updating TPU and VM. This may take around 2 minutes.\n",
      "Updating TPU runtime to pytorch-dev20200325 ...\n",
      "Uninstalling torch-1.5.0a0+d6149a7:\n",
      "  Successfully uninstalled torch-1.5.0a0+d6149a7\n",
      "Uninstalling torchvision-0.6.0a0+3c254fb:\n",
      "  Successfully uninstalled torchvision-0.6.0a0+3c254fb\n",
      "Copying gs://tpu-pytorch/wheels/torch-nightly+20200325-cp36-cp36m-linux_x86_64.whl...\n",
      "/ [1 files][ 83.4 MiB/ 83.4 MiB]                                                \n",
      "Operation completed over 1 objects/83.4 MiB.                                     \n",
      "Copying gs://tpu-pytorch/wheels/torch_xla-nightly+20200325-cp36-cp36m-linux_x86_64.whl...\n",
      "- [1 files][114.5 MiB/114.5 MiB]                                                \n",
      "Operation completed over 1 objects/114.5 MiB.                                    \n",
      "Copying gs://tpu-pytorch/wheels/torchvision-nightly+20200325-cp36-cp36m-linux_x86_64.whl...\n",
      "/ [1 files][  2.5 MiB/  2.5 MiB]                                                \n",
      "Operation completed over 1 objects/2.5 MiB.                                      \n",
      "Processing ./torch-nightly+20200325-cp36-cp36m-linux_x86_64.whl\n",
      "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch==nightly+20200325) (0.16.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch==nightly+20200325) (1.18.2)\n",
      "\u001b[31mERROR: fastai 1.0.60 requires torchvision, which is not installed.\u001b[0m\n",
      "Installing collected packages: torch\n",
      "Done updating TPU runtime: <Response [200]>\n",
      "Successfully installed torch-1.5.0a0+d6149a7\n",
      "Processing ./torch_xla-nightly+20200325-cp36-cp36m-linux_x86_64.whl\n",
      "Installing collected packages: torch-xla\n",
      "  Found existing installation: torch-xla 1.6+e788e5b\n",
      "    Uninstalling torch-xla-1.6+e788e5b:\n",
      "      Successfully uninstalled torch-xla-1.6+e788e5b\n",
      "Successfully installed torch-xla-1.6+e788e5b\n",
      "Processing ./torchvision-nightly+20200325-cp36-cp36m-linux_x86_64.whl\n",
      "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision==nightly+20200325) (7.0.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision==nightly+20200325) (1.18.2)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision==nightly+20200325) (1.12.0)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torchvision==nightly+20200325) (1.5.0a0+d6149a7)\n",
      "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch->torchvision==nightly+20200325) (0.16.0)\n",
      "Installing collected packages: torchvision\n",
      "Successfully installed torchvision-0.6.0a0+3c254fb\n",
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "libomp5 is already the newest version (5.0.1-1).\n",
      "0 upgraded, 0 newly installed, 0 to remove and 25 not upgraded.\n"
     ]
    }
   ],
   "source": [
    "VERSION = \"20200325\"  #@param [\"1.5\" , \"20200325\", \"nightly\"]\n",
    "!curl https://raw.githubusercontent.com/pytorch/xla/master/contrib/scripts/env-setup.py -o pytorch-xla-env-setup.py\n",
    "!python pytorch-xla-env-setup.py --version $VERSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 889,
     "status": "ok",
     "timestamp": 1586045142569,
     "user": {
      "displayName": "Wood Xu",
      "photoUrl": "",
      "userId": "11462779557016257409"
     },
     "user_tz": -480
    },
    "id": "pINQUCy7uYnx",
    "outputId": "2de399d1-4912-42b2-fae0-ada1486210e9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
      "/content/drive/My Drive/Colab\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "%cd drive/My Drive/Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "M-GFtmc8uRRJ"
   },
   "outputs": [],
   "source": [
    "import joblib, time, os, copy, datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch_xla\n",
    "import torch_xla.core.xla_model as xm\n",
    "import torch_xla.debug.metrics as met\n",
    "import torch_xla.distributed.parallel_loader as pl\n",
    "import torch_xla.distributed.xla_multiprocessing as xmp\n",
    "import torch_xla.utils.utils as xu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ImeYAtXsvk_o"
   },
   "source": [
    "### Functions for Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fvYSAko_uVZH"
   },
   "outputs": [],
   "source": [
    "def flatten(ls):\n",
    "     for item in ls:\n",
    "            for child in list(item):\n",
    "                yield child\n",
    "\n",
    "def get_segment_positions(x):\n",
    "    ps = x.segment.split()\n",
    "    ls = []\n",
    "    for i in range(len(ps)-1):\n",
    "        if i == 0:\n",
    "            ls.append([int(ps[i]), int(ps[i+1])])\n",
    "        else:\n",
    "            ls.append([int(ps[i])+1, int(ps[i+1])])        \n",
    "    return ls\n",
    "\n",
    "def get_segment_features(x):\n",
    "    ls = []\n",
    "    for rg in x.positions:\n",
    "        ls.append(x.feature[rg[0]:rg[1]])            \n",
    "    return ls\n",
    "\n",
    "def splitDataFrameList(df,target_column):\n",
    "    def splitListToRows(row,row_accumulator,target_column):\n",
    "        split_row = row[target_column]\n",
    "        for s in split_row:\n",
    "            new_row = row.to_dict()\n",
    "            new_row[target_column] = s\n",
    "            row_accumulator.append(new_row)\n",
    "    new_rows = []\n",
    "    df.apply(splitListToRows,axis=1,args = (new_rows,target_column))\n",
    "    new_df = pd.DataFrame(new_rows)\n",
    "    return new_df\n",
    "                \n",
    "def get_train_data():\n",
    "    training_segment = pd.read_csv('training_segment.txt', header=None, names = ['segment'])\n",
    "    training_segment['feature'] = joblib.load('train_feature.joblib')\n",
    "    training_segment['positions'] = training_segment.apply(lambda x: get_segment_positions(x), axis=1)\n",
    "    training_segment['feature'] = training_segment.apply(lambda x: get_segment_features(x), axis=1)\n",
    "    training_segment = splitDataFrameList(training_segment, 'feature')\n",
    "    training_segment['label'] = list(flatten(joblib.load('train_label.joblib')))\n",
    "    training_segment = training_segment.drop(['segment','positions'], axis = 1)\n",
    "    # Further collapse the data from each segment to each single frame\n",
    "    training_segment = splitDataFrameList(training_segment, 'feature')\n",
    "    return training_segment\n",
    "\n",
    "def get_test_data():\n",
    "    test_segment = pd.read_csv('test_segment.txt', header=None, names = ['segment'])\n",
    "    test_segment['feature'] = joblib.load('test_feature.joblib')\n",
    "    test_segment['positions'] = test_segment.apply(lambda x: get_segment_positions(x), axis=1)\n",
    "    test_segment['feature'] = test_segment.apply(lambda x: get_segment_features(x), axis=1)\n",
    "    test_segment = splitDataFrameList(test_segment, 'feature')\n",
    "    test_segment['ID'] = test_segment.index\n",
    "    test_segment = test_segment.drop(['segment','positions'], axis = 1)\n",
    "    # Further collapse the data from each segment to each single frame\n",
    "    test_segment = splitDataFrameList(test_segment, 'feature')\n",
    "    return test_segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Iu4qX-uQu7UC"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "train_df = get_train_data()\n",
    "print(train_df.feature[0].shape)\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sjfnlY2ivI8r"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "train_sample_ratio = 1\n",
    "train_data = train_df.sample(frac=train_sample_ratio)\n",
    "train_data['feature'] = train_data.apply(lambda x : x[\"feature\"].view(1, 20, 20), axis = 1)\n",
    "train_data['label'] = train_data.apply(lambda x : x[\"label\"] - 1, axis = 1)\n",
    "train_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "R07ZfFOsvq2X"
   },
   "source": [
    "### Functions for Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HTJ3ojhXvebc"
   },
   "outputs": [],
   "source": [
    "def set_parameter_requires_grad(model, feature_extracting):\n",
    "    if feature_extracting:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "def train_model(model, dataloaders, criterion, optimizer, num_epochs=25, is_inception=False):\n",
    "    since = time.time()\n",
    "\n",
    "    val_acc_history = []\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        ms = time.time()\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    if is_inception and phase == 'train':\n",
    "                        outputs, aux_outputs = model(inputs)\n",
    "                        loss1 = criterion(outputs, labels)\n",
    "                        loss2 = criterion(aux_outputs, labels)\n",
    "                        loss = loss1 + 0.4*loss2\n",
    "                    else:\n",
    "                        outputs = model(inputs)\n",
    "                        loss = criterion(outputs, labels)\n",
    "\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
    "            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)           \n",
    "\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            if phase == 'val':\n",
    "                val_acc_history.append(epoch_acc)            \n",
    "            print('{} Loss: {:.4f}, {} Acc: {:.4f}'.format(phase, epoch_loss, phase, epoch_acc))\n",
    "        \n",
    "        time_taken = str(datetime.timedelta(seconds=time.time() - ms))\n",
    "        print('time taken: {}'.format(time_taken))\n",
    "            \n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, val_acc_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1211,
     "status": "ok",
     "timestamp": 1586020192512,
     "user": {
      "displayName": "Wood Xu",
      "photoUrl": "",
      "userId": "11462779557016257409"
     },
     "user_tz": -480
    },
    "id": "v_rF7Ngav5Qa",
    "outputId": "88031fd1-d8e4-4dd5-9c25-34a3aebfd9e0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8 µs, sys: 0 ns, total: 8 µs\n",
      "Wall time: 12.2 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# from models.VGGNet import VGGNet\n",
    "\n",
    "def set_parameter_requires_grad(model, feature_extracting):\n",
    "    if feature_extracting:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "\n",
    "def train_model(model, dataloaders, criterion, optimizer, num_epochs=25, is_inception=False):\n",
    "    print(\"train model starts.....\")\n",
    "    \n",
    "    since = time.time()\n",
    "\n",
    "    val_acc_history = []\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        ms = time.time()\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            para_loader = pl.ParallelLoader(dataloaders[phase], [device])\n",
    "            loader = para_loader.per_device_loader(device)\n",
    "            if phase == 'train':\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            for inputs, labels in loader:\n",
    "                # inputs = inputs.to(device)\n",
    "                # labels = labels.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    if is_inception and phase == 'train':\n",
    "                        outputs, aux_outputs = model(inputs)\n",
    "                        loss1 = criterion(outputs, labels)\n",
    "                        loss2 = criterion(aux_outputs, labels)\n",
    "                        loss = loss1 + 0.4*loss2\n",
    "                    else:\n",
    "                        outputs = model(inputs)\n",
    "                        loss = criterion(outputs, labels)\n",
    "\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        # optimizer.step()\n",
    "                        xm.optimizer_step(optimizer)\n",
    "\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
    "            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)           \n",
    "\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            if phase == 'val':\n",
    "                val_acc_history.append(epoch_acc)\n",
    "            \n",
    "            time_taken = str(datetime.timedelta(seconds=time.time() - ms))\n",
    "            xm.master_print('{} Loss: {:.4f}, {} Acc: {:.4f}, time taken: {}'.format(phase, epoch_loss, phase, epoch_acc, time_taken))\n",
    "            \n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    xm.master_print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    xm.master_print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, val_acc_history\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hhfjRsh4_t1k"
   },
   "source": [
    "### NN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PtitYQc__tCx"
   },
   "outputs": [],
   "source": [
    "class VGGNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VGGNet, self).__init__()\n",
    "        self.conv11 = nn.Conv2d(1, 6, 3, stride=1, padding=2)\n",
    "        self.conv12 = nn.Conv2d(6, 6, 3, stride=1, padding=2)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        self.conv21 = nn.Conv2d(6, 16, 3, stride=1, padding=2)\n",
    "        self.conv22 = nn.Conv2d(16, 16, 3, stride=1, padding=2)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        self.conv31 = nn.Conv2d(16, 64, 3, stride=1, padding=2)\n",
    "        self.conv32 = nn.Conv2d(64, 64, 3, stride=1, padding=2)\n",
    "        self.conv33 = nn.Conv2d(64, 64, 3, stride=1, padding=2)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        self.conv41 = nn.Conv2d(64, 128, 3, stride=1, padding=2)\n",
    "        self.conv42 = nn.Conv2d(128, 128, 3, stride=1, padding=2)\n",
    "        self.conv43 = nn.Conv2d(128, 128, 3, stride=1, padding=2)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        self.conv51 = nn.Conv2d(128, 256, 3, stride=1, padding=2)\n",
    "        self.conv52 = nn.Conv2d(256, 256, 3, stride=1, padding=2)\n",
    "        self.conv53 = nn.Conv2d(256, 256, 3, stride=1, padding=2)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        self.fc1 = nn.Linear(256*6*6, 256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3 = nn.Linear(128, 47)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv11(x))\n",
    "        x = F.relu(self.conv12(x))\n",
    "        x = self.pool(x)\n",
    "\n",
    "        x = F.relu(self.conv21(x))\n",
    "        x = F.relu(self.conv22(x))\n",
    "        x = self.pool(x)\n",
    "\n",
    "        x = F.relu(self.conv31(x))\n",
    "        x = F.relu(self.conv32(x))\n",
    "        x = F.relu(self.conv33(x))\n",
    "        x = self.pool(x)\n",
    "\n",
    "        x = F.relu(self.conv41(x))\n",
    "        x = F.relu(self.conv42(x))\n",
    "        x = F.relu(self.conv43(x))\n",
    "        x = self.pool(x)\n",
    "\n",
    "        x = F.relu(self.conv51(x))\n",
    "        x = F.relu(self.conv52(x))\n",
    "        x = F.relu(self.conv53(x))\n",
    "        x = self.pool(x)\n",
    "\n",
    "        x = x.view(-1, 256*6*6)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return F.log_softmax(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-X74yrA5y3pE"
   },
   "source": [
    "### Setup for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_r6FMfAFw1IX"
   },
   "outputs": [],
   "source": [
    "\n",
    "train_feature = torch.stack(train_data['feature'].tolist())\n",
    "train_label = torch.tensor(train_data['label'].values.astype(np.long))\n",
    "\n",
    "train_dataset = torch.utils.data.TensorDataset(train_feature, train_label)\n",
    "\n",
    "train_size = int(0.98 * len(train_data))\n",
    "val_size = int(0.01 * len(train_data))\n",
    "test_size = len(train_data) - train_size - val_size\n",
    "train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(train_dataset, [train_size, val_size, test_size])\n",
    "\n",
    "train_sampler = torch.utils.data.distributed.DistributedSampler(train_dataset, num_replicas=xm.xrt_world_size(), rank=xm.get_ordinal(), shuffle=True)\n",
    "val_sampler = torch.utils.data.distributed.DistributedSampler(val_dataset, num_replicas=xm.xrt_world_size(), rank=xm.get_ordinal(), shuffle=True)\n",
    "test_sampler = torch.utils.data.distributed.DistributedSampler(test_dataset, num_replicas=xm.xrt_world_size(), rank=xm.get_ordinal(), shuffle=True)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=256, sampler=train_sampler, num_workers=4, drop_last=True)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=256, sampler=val_sampler, num_workers=4, drop_last=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=256, sampler=test_sampler, num_workers=4, drop_last=True)\n",
    "\n",
    "dataloaders_dict = {'train':train_loader, 'val':val_loader}\n",
    "print(\"len(train_loader.dataset) = \", len(train_loader.dataset))\n",
    "print(\"len(val_loader.dataset) = \", len(val_loader.dataset))\n",
    "print(\"len(test_loader.dataset) = \", len(test_loader.dataset))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 913
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 8768,
     "status": "ok",
     "timestamp": 1586045390415,
     "user": {
      "displayName": "Wood Xu",
      "photoUrl": "",
      "userId": "11462779557016257409"
     },
     "user_tz": -480
    },
    "id": "eQj0nsl3qrKP",
    "outputId": "0e3ad1b7-26ff-4c98-c14a-ed3d28568a06"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGGNet(\n",
      "  (conv11): Conv2d(1, 6, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
      "  (conv12): Conv2d(6, 6, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv21): Conv2d(6, 16, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
      "  (conv22): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
      "  (conv31): Conv2d(16, 64, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
      "  (conv32): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
      "  (conv33): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
      "  (conv41): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
      "  (conv42): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
      "  (conv43): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
      "  (conv51): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
      "  (conv52): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
      "  (conv53): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
      "  (fc1): Linear(in_features=9216, out_features=256, bias=True)\n",
      "  (fc2): Linear(in_features=256, out_features=128, bias=True)\n",
      "  (fc3): Linear(in_features=128, out_features=47, bias=True)\n",
      ")\n",
      "Params to learn:\n",
      "\t conv11.weight\n",
      "\t conv11.bias\n",
      "\t conv12.weight\n",
      "\t conv12.bias\n",
      "\t conv21.weight\n",
      "\t conv21.bias\n",
      "\t conv22.weight\n",
      "\t conv22.bias\n",
      "\t conv31.weight\n",
      "\t conv31.bias\n",
      "\t conv32.weight\n",
      "\t conv32.bias\n",
      "\t conv33.weight\n",
      "\t conv33.bias\n",
      "\t conv41.weight\n",
      "\t conv41.bias\n",
      "\t conv42.weight\n",
      "\t conv42.bias\n",
      "\t conv43.weight\n",
      "\t conv43.bias\n",
      "\t conv51.weight\n",
      "\t conv51.bias\n",
      "\t conv52.weight\n",
      "\t conv52.bias\n",
      "\t conv53.weight\n",
      "\t conv53.bias\n",
      "\t fc1.weight\n",
      "\t fc1.bias\n",
      "\t fc2.weight\n",
      "\t fc2.bias\n",
      "\t fc3.weight\n",
      "\t fc3.bias\n"
     ]
    }
   ],
   "source": [
    "\n",
    "num_classes = 47\n",
    "batch_size = 256\n",
    "num_epochs = 10\n",
    "feature_extract = True\n",
    "# num_epochs = 10\n",
    "\n",
    "\n",
    "device = xm.xla_device()\n",
    "model = VGGNet().to(device)\n",
    "print(VGGNet())\n",
    "# model_ft = MyNet().double()\n",
    "# print(model_ft)\n",
    "# model_ft = model_ft.to(device)\n",
    "\n",
    "params_to_update = model.parameters()\n",
    "print(\"Params to learn:\")\n",
    "if feature_extract:\n",
    "    params_to_update = []\n",
    "    for name,param in model.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            params_to_update.append(param)\n",
    "            print(\"\\t\",name)\n",
    "else:\n",
    "    for name,param in model.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            print(\"\\t\",name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3745099,
     "status": "ok",
     "timestamp": 1586024228518,
     "user": {
      "displayName": "Wood Xu",
      "photoUrl": "",
      "userId": "11462779557016257409"
     },
     "user_tz": -480
    },
    "id": "8m2xmqaOyY5d",
    "outputId": "6e9ade35-d41e-4bff-8d10-84345f54de81"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGGNet(\n",
      "  (conv11): Conv2d(1, 6, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
      "  (conv12): Conv2d(6, 6, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv21): Conv2d(6, 16, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
      "  (conv22): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
      "  (conv31): Conv2d(16, 64, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
      "  (conv32): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
      "  (conv33): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
      "  (conv41): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
      "  (conv42): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
      "  (conv43): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
      "  (conv51): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
      "  (conv52): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
      "  (conv53): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
      "  (fc1): Linear(in_features=9216, out_features=256, bias=True)\n",
      "  (fc2): Linear(in_features=256, out_features=128, bias=True)\n",
      "  (fc3): Linear(in_features=128, out_features=47, bias=True)\n",
      ")\n",
      "Params to learn:\n",
      "\t conv11.weight\n",
      "\t conv11.bias\n",
      "\t conv12.weight\n",
      "\t conv12.bias\n",
      "\t conv21.weight\n",
      "\t conv21.bias\n",
      "\t conv22.weight\n",
      "\t conv22.bias\n",
      "\t conv31.weight\n",
      "\t conv31.bias\n",
      "\t conv32.weight\n",
      "\t conv32.bias\n",
      "\t conv33.weight\n",
      "\t conv33.bias\n",
      "\t conv41.weight\n",
      "\t conv41.bias\n",
      "\t conv42.weight\n",
      "\t conv42.bias\n",
      "\t conv43.weight\n",
      "\t conv43.bias\n",
      "\t conv51.weight\n",
      "\t conv51.bias\n",
      "\t conv52.weight\n",
      "\t conv52.bias\n",
      "\t conv53.weight\n",
      "\t conv53.bias\n",
      "\t fc1.weight\n",
      "\t fc1.bias\n",
      "\t fc2.weight\n",
      "\t fc2.bias\n",
      "\t fc3.weight\n",
      "\t fc3.bias\n",
      "train model starts.....\n",
      "Epoch 0/9\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:59: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 3.2577, train Acc: 0.1267, time taken: 0:06:16.408039\n",
      "val Loss: 3.2176, val Acc: 0.1227, time taken: 0:06:25.396365\n",
      "Epoch 1/9\n",
      "----------\n",
      "train Loss: 3.2238, train Acc: 0.1275, time taken: 0:06:12.062088\n",
      "val Loss: 3.2175, val Acc: 0.1227, time taken: 0:06:15.858170\n",
      "Epoch 2/9\n",
      "----------\n",
      "train Loss: 3.2238, train Acc: 0.1275, time taken: 0:06:08.373956\n",
      "val Loss: 3.2175, val Acc: 0.1227, time taken: 0:06:12.149060\n",
      "Epoch 3/9\n",
      "----------\n",
      "train Loss: 3.2237, train Acc: 0.1275, time taken: 0:06:09.385173\n",
      "val Loss: 3.2174, val Acc: 0.1227, time taken: 0:06:13.191269\n",
      "Epoch 4/9\n",
      "----------\n",
      "train Loss: 3.2237, train Acc: 0.1275, time taken: 0:06:09.395568\n",
      "val Loss: 3.2174, val Acc: 0.1227, time taken: 0:06:13.229347\n",
      "Epoch 5/9\n",
      "----------\n",
      "train Loss: 3.2236, train Acc: 0.1275, time taken: 0:06:09.974035\n",
      "val Loss: 3.2172, val Acc: 0.1227, time taken: 0:06:13.806440\n",
      "Epoch 6/9\n",
      "----------\n",
      "train Loss: 3.2208, train Acc: 0.1275, time taken: 0:06:08.456035\n",
      "val Loss: 3.1963, val Acc: 0.1227, time taken: 0:06:12.243672\n",
      "Epoch 7/9\n",
      "----------\n",
      "train Loss: 2.8027, train Acc: 0.2261, time taken: 0:06:08.693633\n",
      "val Loss: 2.4505, val Acc: 0.3003, time taken: 0:06:12.436269\n",
      "Epoch 8/9\n",
      "----------\n",
      "train Loss: 2.2841, train Acc: 0.3426, time taken: 0:06:05.659453\n",
      "val Loss: 2.1373, val Acc: 0.3786, time taken: 0:06:09.435888\n",
      "Epoch 9/9\n",
      "----------\n",
      "train Loss: 2.0082, train Acc: 0.4197, time taken: 0:06:06.072886\n",
      "val Loss: 1.9094, val Acc: 0.4457, time taken: 0:06:09.840082\n",
      "Training complete in 62m 18s\n",
      "Best val Acc: 0.445729\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# def _mp_fn(index):\n",
    "torch.set_default_tensor_type('torch.FloatTensor')\n",
    "optimizer_ft = torch.optim.SGD(params_to_update, lr=0.001, momentum=0.9)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "model_ft, hist = train_model(model, dataloaders_dict, criterion, optimizer_ft, num_epochs=num_epochs, is_inception=False)\n",
    "\n",
    "# xmp.spawn(_mp_fn, nprocs=, start_method='fork')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 86
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 7461,
     "status": "ok",
     "timestamp": 1586024235991,
     "user": {
      "displayName": "Wood Xu",
      "photoUrl": "",
      "userId": "11462779557016257409"
     },
     "user_tz": -480
    },
    "id": "Hia_2brIzBV_",
    "outputId": "45f5a081-8470-414f-f555-356f93f4a8ee"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:59: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of test data: 44.64738175675676\n",
      "CPU times: user 44.4 s, sys: 2.46 s, total: 46.8 s\n",
      "Wall time: 6.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "        outputs = model_ft(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of test data: {0}'.format(100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kbExTAtZGdpJ"
   },
   "source": [
    "### Save and Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WnthUITizIK6"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "## Save the model. Run this if need to save.\n",
    "model_name = \"model_\"  + str(train_sample_ratio) + \".model\"\n",
    "torch.save(model_ft.state_dict(), model_name)\n",
    "# upload_files([model_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1461,
     "status": "ok",
     "timestamp": 1586045403062,
     "user": {
      "displayName": "Wood Xu",
      "photoUrl": "",
      "userId": "11462779557016257409"
     },
     "user_tz": -480
    },
    "id": "LftjIQHH4bZw",
    "outputId": "694009fd-8f01-4f33-f56a-3159fefaea35"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9.24 s, sys: 228 ms, total: 9.47 s\n",
      "Wall time: 730 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "## Load the model from previously saved.\n",
    "model_name = \"model_1\"  +  \".model\"\n",
    "model = VGGNet().double().to(device)\n",
    "model.load_state_dict(torch.load(model_name, map_location=device)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "315IlXqaGimo"
   },
   "source": [
    "### Apply on Test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 344
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 734,
     "status": "ok",
     "timestamp": 1586046610869,
     "user": {
      "displayName": "Wood Xu",
      "photoUrl": "",
      "userId": "11462779557016257409"
     },
     "user_tz": -480
    },
    "id": "4_THZvelvpJZ",
    "outputId": "6e61e812-e6b4-4955-ce7d-6e775183e2bb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGGNet(\n",
      "  (conv11): Conv2d(1, 6, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
      "  (conv12): Conv2d(6, 6, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv21): Conv2d(6, 16, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
      "  (conv22): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
      "  (conv31): Conv2d(16, 64, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
      "  (conv32): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
      "  (conv33): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
      "  (conv41): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
      "  (conv42): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
      "  (conv43): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
      "  (conv51): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
      "  (conv52): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
      "  (conv53): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
      "  (fc1): Linear(in_features=9216, out_features=256, bias=True)\n",
      "  (fc2): Linear(in_features=256, out_features=128, bias=True)\n",
      "  (fc3): Linear(in_features=128, out_features=47, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4WgGieMT4oDj"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "test_df = get_test_data()\n",
    "# test_data = test_df.sample(frac = 1.0)\n",
    "test_df['feature'] = test_df.apply(lambda x : x[\"feature\"].view(1, 20, 20), axis = 1)\n",
    "test_feature = torch.stack(test_df['feature'].tolist())\n",
    "test_dataset = torch.utils.data.TensorDataset(test_feature)\n",
    "predict_loader = torch.utils.data.DataLoader(test_dataset, batch_size=256, shuffle=False)\n",
    "\n",
    "result = []\n",
    "with torch.no_grad():\n",
    "  para_loader = pl.ParallelLoader(predict_loader, [device])\n",
    "  loader = para_loader.per_device_loader(device)\n",
    "  for data in loader:\n",
    "    ouputs = model_ft(data)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    result = np.append(result, predicted)\n",
    "\n",
    "test_df['label'] = np.transpose(result).astype('int') \n",
    "test_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UBkGgGFGGm2B"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "test_result = pd.DataFrame(result.reshape(-1,47))\n",
    "test_result['ID'] = test_data['ID'].values\n",
    "test_data_mean = test_result.groupby('ID')[list(range(47))].agg(['mean'])\n",
    "test_data_mean.columns = list(range(47))\n",
    "test_data_mean[\"Category\"] = test_data_mean.idxmax(axis = 1)\n",
    "test_data_mean['Category'] = test_data_mean.apply(lambda x : x[\"Category\"] + 1, axis = 1).astype('int') \n",
    "test_data_mean[\"ID\"] = test_data_mean.index\n",
    "test_data_group = test_data_mean[['ID','Category']]\n",
    "print(test_data_group.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mE7LAbD1wQAj"
   },
   "outputs": [],
   "source": [
    "submission_name = \"submission_\"  + str(train_sample_ratio) + \"_mean.csv\"\n",
    "test_data_group.to_csv(submission_name, index=False)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "authorship_tag": "ABX9TyPUEL7QhkbIN3g1rywnqxxu",
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "cs5242_tpu_v1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
